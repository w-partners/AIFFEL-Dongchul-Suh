{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4cad55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n",
      "500  images to be resized.\n",
      "500  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "500  images to be resized.\n",
      "500  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "500  images to be resized.\n",
      "500  images resized.\n",
      "보 이미지 resize 완료!\n",
      "학습데이터(x_train)의 이미지 개수는 1500 입니다.\n",
      "x_train shape: (1500, 28, 28, 3)\n",
      "y_train shape: (1500,)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")\n",
    "\n",
    "\n",
    "####################################\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "                                                            # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "####################################\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "                                                            # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "#######################################\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "                                                            # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")\n",
    "\n",
    "#########################################\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=1500):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28                                                            # 이미지 사이즈 28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3884c3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9557 - accuracy: 0.6020\n",
      "Epoch 2/17\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.8300\n",
      "Epoch 3/17\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2634 - accuracy: 0.9360\n",
      "Epoch 4/17\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9573\n",
      "Epoch 5/17\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9800\n",
      "Epoch 6/17\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9920\n",
      "Epoch 7/17\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9873\n",
      "Epoch 8/17\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9980\n",
      "Epoch 9/17\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9993\n",
      "Epoch 10/17\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 11/17\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 12/17\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 13/17\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 14/17\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 15/17\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 16/17\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9993\n",
      "Epoch 17/17\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7febce5bb040>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "                                                            # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3, 3), activation = 'relu', input_shape = (28, 28, 3)))\n",
    "model.add(keras.layers.MaxPool2D(2, 2))\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model.add(keras.layers.MaxPool2D(2, 2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(3, activation = 'softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "####################################################\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe1333d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 997.1900 - accuracy: 0.6500\n",
      "test_loss: 997.1900024414062 \n",
      "test_accuracy: 0.6499999761581421\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "#    print(len(images), \" images to be resized.\")\n",
    "\n",
    "                                                            # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "#.  print(len(images), \" images resized.\")\n",
    "\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "# print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "# print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "# print(\"보 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28                               # 이미지 사이즈 28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "#    print(\"시험데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "# print(\"x_test shape: {}\".format(x_test.shape))\n",
    "# print(\"y_test shape: {}\".format(y_test.shape))\n",
    "\n",
    "\n",
    "################################################\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c61ebb",
   "metadata": {},
   "source": [
    "Exploration 01 평가\n",
    "<br><br>\n",
    "__결과정리__\n",
    "<br><br>\n",
    "- 최초 : Accuracy는 30%정도로 나왔다. \n",
    "     - Dense, Epoch, Conv2D 등 하이퍼파라미터의 값 변경을 통해 Accuracy를 높임\n",
    "- 중간 : Accuracy 40% 정도\n",
    "     - 이미지 해상도를 150으로 변경\n",
    "- 최종 : Accuracy는 60% 정도\n",
    "    - 코드확인을 위해 재실행할 수록 Accuracy가 떨어짐\n",
    "    - 피드백 : Accuracy는 40% 정도\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f0d19c",
   "metadata": {},
   "source": [
    "__정확도 부분__  \n",
    "<br><br>\n",
    "Dense, Epoch, Conv2D 등 하이퍼파라미터의 값 변경하였으나 아무리 높게 나와도 40%를 넘지 못하는 것으로 나왔다.   \n",
    "먼저 콘볼루션 레이어의 값을 32 64로 조정하였으나 정확도가 오히려 떨어지는 현상이 나타났다.   \n",
    "<br>\n",
    "값을 16, 32로 다시 수정하고 Epoch값을 변경하였을 때 정확도의 변화가 생겼다.  \n",
    "최대 40회까지 변경하였으나 20정도에서 가장 높은 값이 나왔으나 40%를 넘지 못하고 Epoch 값을 더 올릴수록 오히려 떨어지는 결과가 나타났다.   \n",
    "\n",
    "> 이런한 결과를 통해 지나친 학습량과 초기 값을 많이 주었을때 오퍼피팅이 나타난다는 것을 알수 있었다. \n",
    "\n",
    "콘볼루션 레이어 수치를 낮게 함으로 오버피팅을 줄일 수 있었으며. Epoch 역시 지나치게 실시하면 오버피팅이 나타나는 것으로 보인다. 이상의 상황으로 정확도를 높이기 위해 이미지 사이즈를 28에서 150으로 높였을 때 정확도가 크게 상승하는 결과를 볼 수 있었다. \n",
    "<br>\n",
    "28 사이즈 일때 학습용 데이터와 테스트 데이터를 확인해보면 사람인 내가 봐도 알아보기 어려울 정도로 이미지가 뭉개지는 것을 볼 수 있었다. \n",
    "또한 배경의 색상과 구분이 어려웠으며 이것이 정확도를 떨어뜨리는 결과를 낳지 않았나 추측된다.\n",
    "<br>\n",
    "이러한 생각에 따라 이미지의 해상도를 높이는 결정을 하였으며 결과는 만족할만한 수준은 아니었으나 정확도의 향상이 있었다. \n",
    "<br>\n",
    "이러한 결과로 볼때 데이터의 품질이 학습에 큰 영향을 끼친다는 것을 확인할 수 있었다. \n",
    "이미지 데이터를 추출하거나 생성할 때 배경을 단색으로 조정하고 대상체의 컨트라스트를 높이면 만족할만한 정확도가 나오지 않을까 추측된다. \n",
    "<br>\n",
    "\n",
    "> 지도학습의 경우 특히 훈련데이터와 테스트 데이터의 품질을 신경쓸 필요가 있을 것 같다.\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06718e0",
   "metadata": {},
   "source": [
    "__코딩부분__\n",
    "<br><br>\n",
    "클래스에 대한 학습이 부족하다는 것을 깨달았다.   \n",
    "코드를 보면 반복된 함수의 사용이 많은 데 이러한 부준을 클래스를 활용하여 코드의 양을 줄일 수 있을 거라 생각하였으나 클래스를 호출하여 사용할 때마다 모듈 에러가 발생하여 여러가지 어려움을 겪었다.   \n",
    "\n",
    "코드가 굉장히 긴편인데 클래스만 제대로 활용할 수 있다면 코드의 길이를 반 이하로 줄일 수 있지 않을 까 생각된다. \n",
    "코드가 길게 나온 이유 중 하나로 중간 중간 에러가 발생하지 않을까 생각되어 중간 결과값을 프린트해주고 확인하면서 진행한 것 때문도 있다. \n",
    "클래스 기능과 클래스 상속 for문을 효과적으로 사용하면 코드의 길이를 줄일 수 있다고 생각한다.   \n",
    "<br>\n",
    "> 앞으로 진행하면서 이 부분을 보완해야 할 것이다.\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5996d4",
   "metadata": {},
   "source": [
    "__궁금한 점__\n",
    "\n",
    "이미지 해상도를 150으로 높여 정확도가 올라갔는데  \n",
    "코드를 재실행할수록 정확도가 떨어지는 문제가 발생되었다. \n",
    "1. 처음 정확도는 61%정도 나왔는데 코드를 확인하기 위해  \n",
    "재실행하는 과정에서 Accuracy가 떨어지는 현상이 나타나고 40%대에 수렴함.   \n",
    " → 이건 도대체 이유를 모르겠음.\n",
    " <br><br>\n",
    "2.주피터 노트북 내에서 재실행하는 것이 인공지능 학습에 영향을 주는 지.   \n",
    "<br><br>\n",
    "3.코드 길이를 줄이기 위해 클래스를 재호출하는 과정에서 알수없는 에러가 나타나는 현상. \n",
    "- 이거 피드백 주시나요? ㅠㅠ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407794ec",
   "metadata": {},
   "source": [
    "__추가 설정 변경__\n",
    "1. Train 데이터를 1500장으로 늘리고 해상도를 낮추는 것으로 더 높은 정확도를 얻게 되었다.\n",
    "\n",
    "> 왜지???  \n",
    "> 이미지 해상도 문제가 있다고 생각했는데  \n",
    "> 이미지 해상도를 낮추었을 때 오히려 정확도가 올라가는 상황이 된 것은...  \n",
    "> 이미지 해상도를 낮춤으로 오히려 오버피팅을 막는 효과가 나왔다고 볼 수 있을 것 같다.  \n",
    "> 단순하게 해상도를 높인다고 해서 나아지는 것은 아니고\n",
    "> 다른 값을 조정하는 것보다 Epoch를 조정하는 것이 가장 정확도를 높이는 데 더 나은 것으로 보인다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7da905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
